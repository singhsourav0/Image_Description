{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtutjSbz417TKIwXsmR+mW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsourav0/Image_Description/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "VGlAiuE5kI__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyxVBxUvj2B2"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "# Upload the fixed image\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "\n",
        "def predict_step(image_paths):\n",
        "  images = []\n",
        "  for image_path in image_paths:\n",
        "    i_image = Image.open(image_path)\n",
        "    if i_image.mode != \"RGB\":\n",
        "      i_image = i_image.convert(mode=\"RGB\")\n",
        "\n",
        "    images.append(i_image)\n",
        "\n",
        "  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "  pixel_values = pixel_values.to(device)\n",
        "\n",
        "  output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "  preds = [pred.strip() for pred in preds]\n",
        "  return preds\n",
        "\n",
        "#********************************************************88\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Image Background Remover\")\n",
        "\n",
        "st.write(\"## Generate Caption From Input Image\")\n",
        "st.write(\n",
        "    \":dog: Try uploading an image to watch the it magically generate caption for you. you can upload your from the sidebar. This code is open source and available [here](https://github.com/singhsourav0/Image_caption) on GitHub.:grin:\"\n",
        ")\n",
        "st.sidebar.write(\"## Upload and copy :gear:\")\n",
        "\n",
        "MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB\n",
        "\n",
        "image_paths = [\"/content/p3.jpeg\"]\n",
        "mood_category = \"happy\"\n",
        "\n",
        "\n",
        "#predict_step(['/content/bike.jpeg'])\n",
        "#print(generated_text)\n",
        "\n",
        "#*************************************************\n",
        "def fix_image(upload):\n",
        "    image = Image.open(upload)\n",
        "    col1.write(\"Your upload Image :camera:\")\n",
        "    col1.image(image)\n",
        "\n",
        "\n",
        "\n",
        "    col2.subheader('Display text')\n",
        "    col2.code('''\n",
        "    col2.write()\n",
        "    predict_step(image_paths)\n",
        "\n",
        "    ''')\n",
        "\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "my_upload = st.sidebar.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if my_upload is not None:\n",
        "    if my_upload.size > MAX_FILE_SIZE:\n",
        "        st.error(\"The uploaded file is too large. Please upload an image smaller than 5MB.\")\n",
        "    else:\n",
        "        fix_image(upload=my_upload)\n",
        "else:\n",
        "    fix_image(\"./p3.jpeg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "id": "7S9VD2w_oXXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &\n",
        "\n",
        "# Wait for the Streamlit app to start (you'll see a link in the output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsChWfr1oYM4",
        "outputId": "78c9f29b-f3d5-4d95-a034-34c30fa1a3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lt --port 8501\n"
      ],
      "metadata": {
        "id": "WkTASxPbofly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpaLomo7o2F7",
        "outputId": "102a7e9c-e2a1-44a5-f52b-29ddab1faa62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.227.82.204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run streamlit1.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ep4-1T2o5sr",
        "outputId": "9e81b086-5487-4bee-f20a-d53ad615bff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session 2ba05128d607700\u001b[0m\u001b[K\r[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\r[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\r[#.................] - fetchMetadata: sill resolveWithNewModule follow-redirect\u001b[0m\u001b[K\r[##................] / fetchMetadata: sill resolveWithNewModule ms@2.1.2 checki\u001b[0m\u001b[K\r\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.82.204:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.196s\n",
            "your url is: https://brave-spoons-design.loca.lt\n",
            "2023-12-30 14:34:05.073647: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-30 14:34:05.073709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-30 14:34:05.075200: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-30 14:34:06.565712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "\n",
        "def predict_step(image_paths):\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        i_image = Image.open(image_path)\n",
        "        if i_image.mode != \"RGB\":\n",
        "            i_image = i_image.convert(mode=\"RGB\")\n",
        "\n",
        "        images.append(i_image)\n",
        "\n",
        "    pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "    pixel_values = pixel_values.to(device)\n",
        "\n",
        "    output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "    preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "n0QxUJgnEfkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stream.py\n",
        "import streamlit as st\n",
        "import app\n",
        "\n",
        "def about():\n",
        "   st.write(\"## About\")\n",
        "    st.write(\"### 🌈 How Deep Learning Works for Image Processing\")\n",
        "    st.write(\n",
        "        \"Deep learning for image processing involves training neural networks on large datasets.\"\n",
        "        \"to learn features and patterns in images. Convolutional Neural Networks (CNNs) are commonly \"\n",
        "        \"used for tasks like image classification, object detection, and image captioning. Pre-trained \"\n",
        "        \"models, like Vision Transformer (ViT), can be fine-tuned for specific image processing tasks.\"\n",
        "    )\n",
        "\n",
        "    container = st.container(border=True)\n",
        "    container.write(\"## make it easy to understand\")\n",
        "\n",
        "    container.write(\"Imagine you have a picture, like a photo of a cat. To make a caption for this picture, a computer needs to look at the image and understand what's happening.Breaking Down the Image:\"\n",
        "\n",
        "        \"the computer uses a special tool (like a super smart camera) to break down the picture into smaller pieces, kind of like noticing different parts of the cat, the background, and so on. Remembering the Important Parts:\"\n",
        "\n",
        "        \"It then remembers the important features of the image, like the cat's ears, eyes, and tail. This is done using a special type of computer brain called a neural network.Understanding Words:\"\n",
        "\n",
        "        \"the computer also knows a lot about words. It understands what words mean and how they fit together. It has learned this from looking at lots of sentences and captions .Putting it Together:\"\n",
        "\n",
        "        \"Now, it's time to combine its knowledge of the picture and its understanding of words. The computers brain, which is like a storyteller, starts putting words together to describe the picture.Getting Better with Practice:\"\n",
        "\n",
        "        \"The computer practices a lot by looking at many pictures and their captions. It learns from these examples to become better at creating its own captions.Teacher Helping Out:\"\n",
        "\n",
        "        \"During this learning process, the computer gets some help from a teacher. The teacher tells the computer if its captions are good or not. The computer tries to improve based on this feedback.Making Captions on its Own:\"\n",
        "\n",
        "        \"Finally, when you show the computer a new picture, it uses what it has learned to create a caption on its own. It looks at the features of the picture and thinks of words to describe them, creating a caption for the image.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def developers():\n",
        "    # Your \"Developers\" tab content goes here\n",
        "    st.write(\"## 🌟 Developers\")\n",
        "    st.write(\"### Meet the Developers\")\n",
        "\n",
        "    # Developer\n",
        "    st.image(\"https://media.licdn.com/dms/image/D4D03AQH-xOdK5K2fHg/profile-displayphoto-shrink_200_200/0/1694320992432?e=1709164800&v=beta&t=L2W5BSfYGiIyPU24tOcnzZHh7yGnXA4WQ1bh_Ykf5tQ\", caption=\"Developer\", use_column_width=True, width=40)\n",
        "    st.write(\"**Name:** SOURAV KUMAR\")\n",
        "    st.write(\"**GitHub:** [sourav kumar](https://github.com/singhsourav0)\")\n",
        "    st.write(\"**LinkedIn:** [Sourav Kumar](https://www.linkedin.com/in/singhsourav0)\")\n",
        "\n",
        "    st.write(\"### 🚀 Future Updates\")\n",
        "    st.write(\n",
        "        \"Stay tuned for future updates and improvements to the Image Caption Generator! \"\n",
        "        \"This project is a stepping stone towards building an Instagram caption generator. \"\n",
        "        \"In the future, it will generate captions like poetry in Hinglish and English, \"\n",
        "        \"complete with emojis and trending hashtags.\"\n",
        "    )\n",
        "\n",
        "def run_streamlit_app():\n",
        "    st.set_page_config(layout=\"wide\", page_title=\"🌈 Image Caption Generator\", page_icon=\"🚀\")\n",
        "\n",
        "    # Main content\n",
        "    st.write(\"# 🌈 Generate Caption From Input Image\")\n",
        "    st.write(\"## :dog: Try uploading an image to watch it magically generate a caption for you.\")\n",
        "    st.sidebar.write(\"## Upload and Copy 🌈\")\n",
        "\n",
        "    # Default image path\n",
        "    default_image_path = \"image/ro.jpg\"\n",
        "\n",
        "    # Display default image (set width to control the size)\n",
        "    image = Image.open(default_image_path)\n",
        "    st.image(image, caption=\"Default Image\", use_column_width=True, width=300)  # Adjust the width as needed\n",
        "\n",
        "    # Display default caption\n",
        "    container = st.container(border=True)\n",
        "    default_caption = app.predict_step([default_image_path])\n",
        "    container.write(\"### Default Image Caption:\")\n",
        "    container.markdown(f\" > # {default_caption[0]}\")\n",
        "\n",
        "    # Display uploaded image and caption\n",
        "    my_upload = st.sidebar.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if my_upload is not None:\n",
        "        if my_upload.size > 5 * 1024 * 1024:  # 5MB\n",
        "            st.error(\"The uploaded file is too large. Please upload an image smaller than 5MB.\")\n",
        "        else:\n",
        "            # Display uploaded image\n",
        "            st.image(my_upload, caption=\"Uploaded Image\", use_column_width=True, width=60)  # Adjust the width as needed\n",
        "\n",
        "            # Call image_caption function with the uploaded image\n",
        "            container = st.container(border=True)\n",
        "            uploaded_caption = app.predict_step([my_upload])\n",
        "            container.write(\"## Uploaded Image Caption:\")\n",
        "            container.markdown(f\"> # {uploaded_caption[0]}\")\n",
        "\n",
        "    # Tabs for \"About\" and \"Developers\"\n",
        "    tabs = st.sidebar.radio(\"Tabs\", (\"About\", \"Developers\"))\n",
        "\n",
        "    # Main content for About and Developers tabs\n",
        "    if tabs == \"About\":\n",
        "        about()\n",
        "    elif tabs == \"Developers\":\n",
        "        developers()\n",
        "\n",
        "    # Add a gif to the sidebar\n",
        "    st.sidebar.image(\"https://media.giphy.com/media/H7CKd1GO6oiZQo7L5d/giphy.gif\", caption=\"Visualize with a GIF\", use_column_width=True)\n",
        "    st.sidebar.image(\"https://media.giphy.com/media/JIX9t2j0ZTN9S/giphy.gif\", caption=\"Visualize with a GIF\", use_column_width=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_streamlit_app()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "HeEcpcokEg25",
        "outputId": "bc3ad5fd-4c2f-488d-eba7-7946e4bfb304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cdbd30fee514>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# stream.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#import app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_streamlit_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/streamlit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Set Streamlit page config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Image Caption Generator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Main content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'streamlit' has no attribute 'set_page_config' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RlpuLzKgGVEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeBg7KUGFBia"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}